#!/usr/bin/env python3
"""
æ™ºèƒ½ç½‘ç«™çˆ¬è™« - é›†æˆå¯åŠ¨è„šæœ¬
æ”¯æŒå¢å¼ºå¯¼èˆªåŠŸèƒ½çš„ç»Ÿä¸€å¯åŠ¨å…¥å£
"""

import sys
import os
import argparse
from pathlib import Path
from typing import Optional

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    required_packages = [
        ('crawl4ai', 'crawl4ai'),
        ('beautifulsoup4', 'bs4'),
        ('flask', 'flask'),
        ('flask-cors', 'flask_cors'),
        ('flask-socketio', 'flask_socketio')
    ]
    
    missing_packages = []
    
    for package_name, import_name in required_packages:
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"   - {package}")
        
        print("\nğŸ“¦ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        print("pip install -r requirements.txt")
        print("\næˆ–è€…å•ç‹¬å®‰è£…:")
        print("pip install " + " ".join(missing_packages))
        return False
    
    return True

def check_enhanced_navigation():
    """æ£€æŸ¥å¢å¼ºå¯¼èˆªåŠŸèƒ½çŠ¶æ€"""
    enhanced_nav_file = Path("enhanced_navigation_extractor.py")
    
    if enhanced_nav_file.exists():
        try:
            # å°è¯•å¯¼å…¥æµ‹è¯•
            from enhanced_navigation_extractor import EnhancedNavigationExtractor
            print("âœ… å¢å¼ºå¯¼èˆªåŠŸèƒ½å¯ç”¨")
            return True
        except Exception as e:
            print(f"âŒ å¢å¼ºå¯¼èˆªåŠŸèƒ½å¯¼å…¥å¤±è´¥: {e}")
            return False
    else:
        print("âš ï¸  å¢å¼ºå¯¼èˆªåŠŸèƒ½ä¸å¯ç”¨ - æ–‡ä»¶ä¸å­˜åœ¨")
        return False

def display_startup_info():
    """æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯"""
    print("ğŸš€ æ™ºèƒ½ç½‘ç«™çˆ¬è™« - é›†æˆå¯åŠ¨è„šæœ¬")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–...")
    deps_ok = check_dependencies()
    
    # æ£€æŸ¥å¢å¼ºå¯¼èˆªåŠŸèƒ½
    print("\nğŸ” æ£€æŸ¥å¢å¼ºå¯¼èˆªåŠŸèƒ½...")
    enhanced_nav_ok = check_enhanced_navigation()
    
    if enhanced_nav_ok:
        print("\nğŸ¯ å¢å¼ºå¯¼èˆªåŠŸèƒ½ç‰¹æ€§:")
        print("   â€¢ 15ç§ä¸“ä¸šå¯¼èˆªé€‰æ‹©å™¨ï¼ˆvs åŸæ¥çš„3ç§ï¼‰")
        print("   â€¢ å®Œæ•´HTMLç»“æ„ä¿ç•™ï¼ˆvs åŸæ¥çš„çº¯æ–‡æœ¬ï¼‰")
        print("   â€¢ å¤šå±‚çº§å¯¼èˆªè¯†åˆ«")
        print("   â€¢ æ™ºèƒ½é“¾æ¥æå–å’Œå»é‡")
        print("   â€¢ å¯¼èˆªç»“æ„åˆ†æå’ŒæŠ¥å‘Š")
        print("   â€¢ ä¸ç°æœ‰ç³»ç»Ÿå®Œå…¨å…¼å®¹")
    
    print("\n" + "=" * 50)
    
    return deps_ok, enhanced_nav_ok

def start_web_server():
    """å¯åŠ¨WebæœåŠ¡å™¨"""
    print("ğŸŒ å¯åŠ¨WebæœåŠ¡å™¨...")
    
    # æ£€æŸ¥Webç›®å½•å’Œå¯åŠ¨è„šæœ¬
    web_dir = Path("web")
    start_script = web_dir / "start.py"
    
    if not web_dir.exists():
        print("âŒ Webç›®å½•ä¸å­˜åœ¨")
        return False
    
    if not start_script.exists():
        print("âŒ WebæœåŠ¡å™¨å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨")
        print("   è¯·ç¡®ä¿ web/start.py æ–‡ä»¶å­˜åœ¨")
        return False
    
    try:
        # ä½¿ç”¨subprocessè¿è¡ŒWebæœåŠ¡å™¨
        import subprocess
        
        # åˆ‡æ¢åˆ°Webç›®å½•å¹¶è¿è¡Œå¯åŠ¨è„šæœ¬
        result = subprocess.run([
            sys.executable, "start.py"
        ], cwd=str(web_dir), capture_output=False)
        
        return result.returncode == 0
        
    except Exception as e:
        print(f"âŒ WebæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤:")
        print("   1. ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²å®‰è£…: pip install -r requirements.txt")
        print("   2. æ£€æŸ¥ç«¯å£5000æ˜¯å¦è¢«å ç”¨")
        print("   3. ç¡®ä¿web/start.pyæ–‡ä»¶å­˜åœ¨ä¸”æ— è¯­æ³•é”™è¯¯")
        return False

def start_command_line(url: str, output_dir: Optional[str] = None):
    """å¯åŠ¨å‘½ä»¤è¡Œç‰ˆæœ¬"""
    print(f"ğŸ’» å¯åŠ¨å‘½ä»¤è¡Œç‰ˆæœ¬...")
    print(f"ğŸŒ ç›®æ ‡URL: {url}")
    
    # å¯¼å…¥å¹¶è¿è¡Œçˆ¬è™«
    try:
        import asyncio
        
        # ç¡®ä¿å½“å‰ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
        current_dir = str(Path.cwd())
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        
        from website_crawler import WebsiteCrawler
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        output_dir = output_dir or f"crawl_results_{Path(url).name}"
        crawler = WebsiteCrawler(url, output_dir)
        
        # è¿è¡Œçˆ¬è™«
        async def run_crawler():
            try:
                # å‘ç°ç½‘ç«™ç»“æ„
                discovered_urls = await crawler.discover_website_structure(
                    max_depth=3,
                    max_pages=50
                )
                
                # æŠ“å–æ‰€æœ‰å†…å®¹
                results = await crawler.crawl_all_content(
                    discovered_urls,
                    batch_size=5
                )
                
                print(f"\nğŸ“Š æŠ“å–å®Œæˆ:")
                print(f"  âœ… æˆåŠŸæŠ“å–: {results['successful_crawls']} ä¸ªé¡µé¢")
                print(f"  âŒ å¤±è´¥é¡µé¢: {results['failed_crawls']} ä¸ªé¡µé¢")
                print(f"  ğŸ“ è¾“å‡ºç›®å½•: {results['output_directory']}")
                
                return True
                
            except Exception as e:
                print(f"âŒ çˆ¬è™«æ‰§è¡Œå¤±è´¥: {str(e)}")
                return False
        
        # è¿è¡Œå¼‚æ­¥å‡½æ•°
        success = asyncio.run(run_crawler())
        return success
        
    except Exception as e:
        print(f"âŒ å‘½ä»¤è¡Œç‰ˆæœ¬å¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½ç½‘ç«™çˆ¬è™« - é›†æˆå¯åŠ¨è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python start_crawler.py web                    # å¯åŠ¨Webç•Œé¢
  python start_crawler.py cli https://example.com  # å‘½ä»¤è¡Œæ¨¡å¼
  python start_crawler.py cli https://example.com --output my_results  # æŒ‡å®šè¾“å‡ºç›®å½•
        """
    )
    
    parser.add_argument(
        'mode',
        choices=['web', 'cli'],
        help='å¯åŠ¨æ¨¡å¼: web (Webç•Œé¢) æˆ– cli (å‘½ä»¤è¡Œ)'
    )
    
    parser.add_argument(
        'url',
        nargs='?',
        help='ç›®æ ‡ç½‘ç«™URL (å‘½ä»¤è¡Œæ¨¡å¼å¿…éœ€)'
    )
    
    parser.add_argument(
        '--output', '-o',
        help='è¾“å‡ºç›®å½• (ä»…å‘½ä»¤è¡Œæ¨¡å¼)'
    )
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    deps_ok, enhanced_nav_ok = display_startup_info()
    
    if not deps_ok:
        print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–åŒ…")
        sys.exit(1)
    
    # æ ¹æ®æ¨¡å¼å¯åŠ¨
    if args.mode == 'web':
        print("\nğŸŒ å¯åŠ¨Webç•Œé¢æ¨¡å¼...")
        success = start_web_server()
    elif args.mode == 'cli':
        if not args.url:
            print("âŒ å‘½ä»¤è¡Œæ¨¡å¼éœ€è¦æä¾›ç›®æ ‡URL")
            parser.print_help()
            sys.exit(1)
        
        print("\nğŸ’» å¯åŠ¨å‘½ä»¤è¡Œæ¨¡å¼...")
        success = start_command_line(args.url, args.output)
    else:
        parser.print_help()
        sys.exit(1)
    
    if success:
        print("\nâœ… ç¨‹åºæ‰§è¡Œå®Œæˆ")
    else:
        print("\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main() 